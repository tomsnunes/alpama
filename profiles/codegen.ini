; codegen
model               = codegen-6B-multi-ggml-4bit-quant.bin
; lora                = cabrita-lora-v0-1/ggml-adapter-model.bin
ctx_size            = 2048
color               =

; batch_size          = 256
; top_k               = 12
; top_p               = 1
; temp                = 0.36
; repeat_penalty      = 1.05

n_predict           = -1
threads             = 12
instruct            =
interactive-first   =
ignore-eos          =

keep                = -1
file                = alpaca.txt

; reverse-prompt      =   "### Human:,### Assistant:"